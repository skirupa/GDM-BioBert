{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3605,
     "status": "ok",
     "timestamp": 1679075791770,
     "user": {
      "displayName": "19PT24 - S KIRUPA",
      "userId": "12629547787028680648"
     },
     "user_tz": -330
    },
    "id": "RvaNWdrKgXjD",
    "outputId": "7fe66ab5-ecad-49ad-f8f1-6398703962bc"
   },
   "outputs": [],
   "source": [
    "#We extract the pubmed document in BioCJSON format\n",
    "import urllib3\n",
    "import json\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "pmcid = 'PMC2837563'\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "\n",
    "r = http.request('GET', f'https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/biocjson?pmcids={pmcid}')\n",
    "data = json.loads(r.data.decode('utf-8'))\n",
    "#data = json.dumps(data, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1679075793852,
     "user": {
      "displayName": "19PT24 - S KIRUPA",
      "userId": "12629547787028680648"
     },
     "user_tz": -330
    },
    "id": "-3bUHWus1nUq",
    "outputId": "3f1c4784-c8ea-473b-d8bb-aefd779ea62b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEvery PMC id has passages.\\nEvery passage has many {infons, offset, text, sentences, annotations, relations}.\\nHere, text is the actual text we have to annotate. \\nEvery annotations has {id, infons, text, locations}. \\nHere infons has {identifier, type} (optional: ncbi-homologene if type is gene).\\nAlso locations has {offset, length}.\\n\\nPassages:\\n    a)infons - data realted article id, author, etc..\\n    b)offset - location index\\n    c)text - whole medical data (sentence) in which medical terms (gene name or disease name) are to be annotated.\\n    d)sentences - not required here\\n    e)annotations:\\n        1)id - key index\\n        2)infons:\\n              a)identifier\\n              b)type - \"Gene\" or \"Disease\" etc.,\\n        3)text - gene name or disease name etc., (Eg: \"K-Ras\")\\n        4)locations:\\n            a)offset - location index\\n            b)length - length of text. (Eg: len(\"tumours\") = 7) \\n    f)relations\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = json.dumps(data, indent=4)\n",
    "#print(output)\n",
    "\n",
    "'''\n",
    "Every PMC id has passages.\n",
    "Every passage has many {infons, offset, text, sentences, annotations, relations}.\n",
    "Here, text is the actual text we have to annotate. \n",
    "Every annotations has {id, infons, text, locations}. \n",
    "Here infons has {identifier, type} (optional: ncbi-homologene if type is gene).\n",
    "Also locations has {offset, length}.\n",
    "\n",
    "Passages:\n",
    "    a)infons - data realted article id, author, etc..\n",
    "    b)offset - location index\n",
    "    c)text - whole medical data (sentence) in which medical terms (gene name or disease name) are to be annotated.\n",
    "    d)sentences - not required here\n",
    "    e)annotations:\n",
    "        1)id - key index\n",
    "        2)infons:\n",
    "              a)identifier\n",
    "              b)type - \"Gene\" or \"Disease\" etc.,\n",
    "        3)text - gene name or disease name etc., (Eg: \"K-Ras\")\n",
    "        4)locations:\n",
    "            a)offset - location index\n",
    "            b)length - length of text. (Eg: len(\"tumours\") = 7) \n",
    "    f)relations\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3EkWKX8wA1b5"
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(columns=['index','sentence'])\n",
    "df2 = pd.DataFrame(columns=['index','sentence','Gene','Mutation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSMLCcRaAlL_"
   },
   "source": [
    "**Annotations for Gene and Mutation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kbIqNKyCgkuF"
   },
   "outputs": [],
   "source": [
    "sentence_index = 0\n",
    "sentence_entities = {}\n",
    "for i in data['passages']:\n",
    "  if i['infons']['section_type'] != 'TABLE':\n",
    "    #filter the table segment\n",
    "    text = i['text']\n",
    "    # print(\"TEXT: \", text)\n",
    "    offset = i['offset']\n",
    "    # print(\"OFFSET: \", offset)    \n",
    "    annotations = i['annotations']\n",
    "    \n",
    "    annotations = sorted(annotations, key = lambda x: x['locations'][0]['offset'])\n",
    "    # print(\"ANNOTATIONS: \", annotations)\n",
    "    #Filter to only include gene-disease annotations\n",
    "    annotations = [annotation for annotation in annotations if ((annotation['infons']['type']=='Gene') or (annotation['infons']['type']=='Mutation'))]\n",
    "    #List all possible combinations of annotations\n",
    "    annots_combinations = list(combinations(annotations, 2))\n",
    "    # print(\"ANNOT COMBIMNATIONS: \", annots_combinations)\n",
    "    #Filter combinations to only include gene-disease combinations\n",
    "    annots_combinations = [annots for annots in annots_combinations if annots[0]['infons']['type'] != annots[1]['infons']['type']]\n",
    "    # print(\"ANNOT COMBINATIONS - GENE-DISEASE: \", annots_combinations)\n",
    "\n",
    "    #processing sentences\n",
    "    sentences = text.split('. ')\n",
    "    # print(sentences)\n",
    "    sentence_offset = {}\n",
    "    sentence_len = {}\n",
    "    prev_sent_offset = offset\n",
    "\n",
    "    for sentence in sentences:\n",
    "\n",
    "      sentence_offset[sentence] = prev_sent_offset\n",
    "      current_sentence_offset = prev_sent_offset\n",
    "      sentence_len[sentence] = len(sentence)\n",
    "      current_sentence_len = len(sentence)\n",
    "      prev_sent_offset += len(sentence) + 2\n",
    "      \n",
    "\n",
    "      #Point to note: Duplicate sentences for as many combinations as present. \n",
    "      for annots in annots_combinations:\n",
    "        difference = 0\n",
    "        current_sentence = sentence\n",
    "        #sort the tuple\n",
    "        annots = sorted(annots, key = lambda x: x['locations'][0]['offset'])\n",
    "\n",
    "        entity_1 = annots[0]\n",
    "        entity_2 = annots[1]\n",
    "        \n",
    "        entity_1_offset = entity_1['locations'][0]['offset']\n",
    "        entity_2_offset = entity_2['locations'][0]['offset']\n",
    "\n",
    "        entity_1_dist = entity_1_offset - current_sentence_offset\n",
    "        entity_2_dist = entity_2_offset - current_sentence_offset\n",
    "\n",
    "        if (0 <= entity_1_dist <= ((current_sentence_len - len(entity_1['text'])) + 1)) and (0 <= entity_2_dist <= ((current_sentence_len - len(entity_2['text'])) + 1)):\n",
    "          #the pair of annotations fall within the sentence\n",
    "          sentence_entities[sentence_index] = (entity_1['text'], entity_2['text'])\n",
    "\n",
    "          entity_1_type = entity_1['infons']['type']\n",
    "          entity_1_length = entity_1['locations'][0]['length']\n",
    "          temp = '@'+ entity_1_type +'$'\n",
    "          entity_1_final_off = entity_1_dist \n",
    "          current_sentence = current_sentence[:entity_1_final_off] + \"@\" + entity_1_type + \"$\" + current_sentence[(entity_1_final_off + entity_1_length):]\n",
    "          difference += (entity_1_length - len(temp))\n",
    "          entity_2_type = entity_2['infons']['type']\n",
    "          entity_2_length = entity_2['locations'][0]['length']\n",
    "          temp = '@'+ entity_2_type +'$'\n",
    "          entity_2_final_off = entity_2_dist - (difference)\n",
    "          current_sentence = current_sentence[:entity_2_final_off] + \"@\" + entity_2_type + \"$\" + current_sentence[(entity_2_final_off + entity_2_length):]\n",
    "          difference += (entity_2_length - len(temp))\n",
    "          # tsv_writer_1.writerow([sentence_index, current_sentence])\n",
    "          row1 = [sentence_index,current_sentence]\n",
    "          df1.loc[len(df1)] = row1\n",
    "          if (entity_1['infons']['type'] == 'Gene'):\n",
    "            # print('Writing...', [sentence_index, sentence, entity_1['text'], entity_2['text']])\n",
    "            # tsv_writer_2.writerow([sentence_index, sentence, entity_1['text'], entity_2['text']])\n",
    "            row2 = [sentence_index, sentence, entity_1['text'], entity_2['text']]\n",
    "            df2.loc[len(df2)] = row2\n",
    "          else:\n",
    "            # print('Writing')\n",
    "            # tsv_writer_2.writerow([sentence_index, sentence, entity_2['text'], entity_1['text']])\n",
    "            row2 = [sentence_index, sentence, entity_2['text'], entity_1['text']]\n",
    "            df2.loc[len(df2)] = row2\n",
    "          sentence_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rax5aqQmrZp-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/skirupa/Desktop/sem8/RSL-Lab/RSLLab-20230318T070434Z-001/RSLLab/project-sample\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir('../biobert-pytorch/relation-extraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Oe0kay_JgprA"
   },
   "outputs": [],
   "source": [
    "df2.to_csv('pub_original_sentences_GM.tsv', sep=\"\\t\", index=False)\n",
    "df1.to_csv('inputGM/test.tsv', sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZSYZQAAi5db"
   },
   "source": [
    "**BioBert Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/skirupa/Desktop/sem8/RSL-Lab/RSLLab-20230318T070434Z-001/RSLLab/biobert-pytorch/relation-extraction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all datasets including NER/RE/QA\n",
    "#!bash ./download.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/skirupa/Desktop/sem8/RSL-Lab/RSLLab-20230318T070434Z-001/RSLLab/biobert-pytorch\n",
      "/home/skirupa/Desktop/sem8/RSL-Lab/RSLLab-20230318T070434Z-001/RSLLab/biobert-pytorch/relation-extraction\n",
      "*****  euadr  Preprocessing Start *****\n",
      "*****  euadr  Preprocessing Done *****\n",
      "*****  GAD  Preprocessing Start *****\n",
      "*****  GAD  Preprocessing Done *****\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('relation-extraction')\n",
    "print(os.getcwd())\n",
    "#To preprocess the datasets downloaded\n",
    "!bash ./preprocess.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8981,
     "status": "ok",
     "timestamp": 1679070353775,
     "user": {
      "displayName": "19PT24 - S KIRUPA",
      "userId": "12629547787028680648"
     },
     "user_tz": -330
    },
    "id": "jPCXvCJLkLsy",
    "outputId": "b2ffa5ef-ecb7-4bd9-dbe3-640d4f36ddcc"
   },
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1679070381883,
     "user": {
      "displayName": "19PT24 - S KIRUPA",
      "userId": "12629547787028680648"
     },
     "user_tz": -330
    },
    "id": "uv7yHEmWkPk8",
    "outputId": "678d9197-a2d7-41d0-fa94-9dc9a2532ad6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SAVE_DIR=./outputGM\n",
      "env: DATA=\"GAD\"\n",
      "env: SPLIT=\"1\"\n",
      "env: DATA_DIR=./inputGM\n",
      "env: ENTITY=${DATA}-${SPLIT}\n",
      "env: MAX_LENGTH=128\n",
      "env: BATCH_SIZE=32\n",
      "env: NUM_EPOCHS=3\n",
      "env: SAVE_STEPS=1000\n",
      "env: SEED=1\n"
     ]
    }
   ],
   "source": [
    "%env SAVE_DIR=./outputGM\n",
    "%env DATA=\"GAD\"\n",
    "%env SPLIT=\"1\"\n",
    "%env DATA_DIR=./inputGM\n",
    "%env ENTITY=${DATA}-${SPLIT}\n",
    "\n",
    "%env MAX_LENGTH=128\n",
    "%env BATCH_SIZE=32\n",
    "%env NUM_EPOCHS=3\n",
    "%env SAVE_STEPS=1000\n",
    "%env SEED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7095,
     "status": "ok",
     "timestamp": 1679070394106,
     "user": {
      "displayName": "19PT24 - S KIRUPA",
      "userId": "12629547787028680648"
     },
     "user_tz": -330
    },
    "id": "Nap7OsDNomOM",
    "outputId": "4ba15580-e24e-4619-f13d-fb35ad41f6ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/18/2023 16:02:46 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
      "03/18/2023 16:02:59 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./outputGM', overwrite_output_dir=True, do_train=False, do_eval=False, do_predict=True, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Mar18_16-02-46_skirupa', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='./outputGM', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
      "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1 were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "03/18/2023 16:03:05 - INFO - root -   *** Test ***\n",
      "100%|███████████████████████████████████████████| 15/15 [00:14<00:00,  1.02s/it]/home/skirupa/miniconda3/envs/env1/lib/python3.6/site-packages/transformers/trainer.py:1118: FutureWarning: This method is deprecated, use `Trainer.is_world_process_zero()` instead.\n",
      "  warnings.warn(\"This method is deprecated, use `Trainer.is_world_process_zero()` instead.\", FutureWarning)\n",
      "03/18/2023 16:03:21 - INFO - __main__ -   ***** Test results sst-2 *****\n",
      "100%|███████████████████████████████████████████| 15/15 [00:14<00:00,  1.04it/s]\n"
     ]
    }
   ],
   "source": [
    "!python run_re.py --task_name SST-2 --config_name bert-base-cased --model_name_or_path dmis-lab/biobert-base-cased-v1.1 \\\n",
    "        --do_predict --data_dir ${DATA_DIR} \\\n",
    "        --output_dir ${SAVE_DIR} \\\n",
    "        --overwrite_output_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "error",
     "timestamp": 1679064615235,
     "user": {
      "displayName": "19PT24 - S KIRUPA",
      "userId": "12629547787028680648"
     },
     "user_tz": -330
    },
    "id": "QgHoYa6Noo9w",
    "outputId": "6af921bc-1802-4a23-bb95-187243510d51"
   },
   "outputs": [],
   "source": [
    "original_sentences = pd.read_csv('pub_original_sentences_GM.tsv', sep=\"\\t\")\n",
    "predictions = pd.read_csv('outputGM/test_results.txt', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QX9DHYpyBbeC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Mutation</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Four additional K-Ras mutations (Leu19Phe (1 o...</td>\n",
       "      <td>K-Ras</td>\n",
       "      <td>Leu19Phe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Four additional K-Ras mutations (Leu19Phe (1 o...</td>\n",
       "      <td>K-Ras</td>\n",
       "      <td>Lys117Asn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Four additional K-Ras mutations (Leu19Phe (1 o...</td>\n",
       "      <td>K-Ras</td>\n",
       "      <td>Ala146Thr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Four additional K-Ras mutations (Leu19Phe (1 o...</td>\n",
       "      <td>K-Ras</td>\n",
       "      <td>Arg164Gln</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Lys117Asn and Ala146Thr had phenotypes similar...</td>\n",
       "      <td>K-Ras</td>\n",
       "      <td>Lys117Asn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>(B) The transforming potential of L19F, K117N,...</td>\n",
       "      <td>K-Ras</td>\n",
       "      <td>A146T</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>(B) The transforming potential of L19F, K117N,...</td>\n",
       "      <td>K-Ras</td>\n",
       "      <td>R164Q</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>(B) The transforming potential of L19F, K117N,...</td>\n",
       "      <td>K-Ras</td>\n",
       "      <td>G12V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>The K-Ras G12V construct was included as a pos...</td>\n",
       "      <td>K-Ras</td>\n",
       "      <td>G12V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>The K-Ras G12V construct was included as a pos...</td>\n",
       "      <td>K-Ras</td>\n",
       "      <td>G12V</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                           sentence   Gene  \\\n",
       "0        0  Four additional K-Ras mutations (Leu19Phe (1 o...  K-Ras   \n",
       "1        1  Four additional K-Ras mutations (Leu19Phe (1 o...  K-Ras   \n",
       "2        2  Four additional K-Ras mutations (Leu19Phe (1 o...  K-Ras   \n",
       "3        3  Four additional K-Ras mutations (Leu19Phe (1 o...  K-Ras   \n",
       "4        4  Lys117Asn and Ala146Thr had phenotypes similar...  K-Ras   \n",
       "..     ...                                                ...    ...   \n",
       "115    115  (B) The transforming potential of L19F, K117N,...  K-Ras   \n",
       "116    116  (B) The transforming potential of L19F, K117N,...  K-Ras   \n",
       "117    117  (B) The transforming potential of L19F, K117N,...  K-Ras   \n",
       "118    118  The K-Ras G12V construct was included as a pos...  K-Ras   \n",
       "119    119  The K-Ras G12V construct was included as a pos...  K-Ras   \n",
       "\n",
       "      Mutation  prediction  \n",
       "0     Leu19Phe           1  \n",
       "1    Lys117Asn           1  \n",
       "2    Ala146Thr           1  \n",
       "3    Arg164Gln           1  \n",
       "4    Lys117Asn           1  \n",
       "..         ...         ...  \n",
       "115      A146T           1  \n",
       "116      R164Q           1  \n",
       "117       G12V           1  \n",
       "118       G12V           1  \n",
       "119       G12V           1  \n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge the pub original sentences and test results (prediction of biobert model)\n",
    "\n",
    "final_re_output = pd.merge(original_sentences, predictions, on ='index', how='left')\n",
    "final_re_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('outputGM')\n",
    "final_re_output.to_csv('final_GM_output.tsv', sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
